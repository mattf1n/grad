@article{Ravfogel2021CounterfactualIR,
  title={Counterfactual Interventions Reveal the Causal Effect of Relative Clause Representations on Agreement Prediction},
  author={Shauli Ravfogel and Grusha Prasad and Tal Linzen and Yoav Goldberg},
  journal={ArXiv},
  year={2021},
  volume={abs/2105.06965}
}

@article{Ban2022TestingPL,
  title={Testing Pre-trained Language Models' Understanding of Distributivity via Causal Mediation Analysis},
  author={Pangbo Ban and Yifan Jiang and Tianran Liu and Shane Steinert-Threlkeld},
  journal={ArXiv},
  year={2022},
  volume={abs/2209.04761}
}

@article{Finlayson2021CausalAO,
  title={Causal Analysis of Syntactic Agreement Mechanisms in Neural Language Models},
  author={Matthew Finlayson and Aaron Mueller and Stuart M. Shieber and Sebastian Gehrmann and Tal Linzen and Yonatan Belinkov},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.06087}
}

@article{Finlayson2022WhatMI,
  title={What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment},
  author={Matthew Finlayson and Kyle Richardson and Ashish Sabharwal and Peter Clark},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.09148}
}

@InProceedings{Mishra2022Lila,
  title={\textsc{L\={\i}la}: A Unified Benchmark for Mathematical Reasoning},
  author={Matthew Finlayson and Swaroop Mishra and Pan Lu and Leonard Tang and Sean Welleck and Chitta Baral and Tanmay Rajpurohit and Oyvind Tafjord and Ashish Sabharwal and Peter Clark and Ashwin Kalyan},
  journal={EMNLP},
  year={2022},
}

@article{Merrill2022LogPrecisionTA,
  title={Log-Precision Transformers are Constant-Depth Uniform Threshold Circuits},
  author={William Cooper Merrill and Ashish Sabharwal},
  journal={ArXiv},
  year={2022},
  volume={abs/2207.00729}
}

@article{Hahn2020TheoreticalLO,
  title={Theoretical Limitations of Self-Attention in Neural Sequence Models},
  author={Michael Hahn},
  journal={Transactions of the Association for Computational Linguistics},
  year={2020},
  volume={8},
  pages={156-171}
}

@inproceedings{Bogin2022UnobservedLS,
  title={Unobserved Local Structures Make Compositional Generalization Hard},
  author={Ben Bogin and Shivanshu Gupta and Jonathan Berant},
  year={2022}
}

@inproceedings{Dobreva2021InvestigatingNI,
  title={Investigating Negation in Pre-trained Vision-and-language Models},
  author={Radina Dobreva and Frank Keller},
  booktitle={BLACKBOXNLP},
  url={https://www.semanticscholar.org/paper/Investigating-Negation-in-Pre-trained-Models-Dobreva-Keller/0996f1d395a5226dcc38fe0e58c7b7f9433e29e5},
  year={2021}
}

@inproceedings{mishra2021crosstask,
      title={Cross-Task Generalization via Natural Language Crowdsourcing Instructions}, 
      author={Swaroop Mishra and Daniel Khashabi and Chitta Baral and Hannaneh Hajishirzi},
      year={2022},
      booktitle={ACL},
      url={https://arxiv.org/abs/2104.08773}
}

@inproceedings{
Wei2021FinetunedLM,
title={Finetuned Language Models are Zero-Shot Learners},
author={Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V Le},
booktitle={ICLR},
year={2022},
url={https://openreview.net/forum?id=gEZrGCozdqR},   
annote={Google researchers build FLAN: an instruction following fine-tuned LM},
}

@inproceedings{Lake2018GeneralizationWS,
  title={Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks},
  author={Brenden M. Lake and Marco Baroni},
  booktitle={ICML},
  year={2018}
}

@article{Khot2022DecomposedPA,
  title={Decomposed Prompting: A Modular Approach for Solving Complex Tasks},
  author={Tushar Khot and H. Trivedi and Matthew Finlayson and Yao Fu and Kyle Richardson and Peter Clark and Ashish Sabharwal},
  journal={ArXiv},
  year={2022},
  volume={abs/2210.02406}
}

@article{Brown2020LanguageMA,
  title={Language Models are Few-Shot Learners},
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and T. J. Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeff Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.14165}
}

@article{Min2022RethinkingTR,
  title={Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?},
  author={Sewon Min and Xinxi Lyu and Ari Holtzman and Mikel Artetxe and Mike Lewis and Hannaneh Hajishirzi and Luke Zettlemoyer},
  journal={ArXiv},
  year={2022},
  volume={abs/2202.12837}
}

@article{Gao2021MakingPL,
  title={Making Pre-trained Language Models Better Few-shot Learners},
  author={Tianyu Gao and Adam Fisch and Danqi Chen},
  journal={ArXiv},
  year={2021},
  volume={abs/2012.15723},
  annote={},
  url={https://aclanthology.org/2021.acl-long.295/}
}
https://aclanthology.org/2021.acl-long.295.pdf
~/papers/Gao2021MakingPL.pdf

@article{Shin2020ElicitingKF,
  title={Eliciting Knowledge from Language Models Using Automatically Generated Prompts},
  author={Taylor Shin and Yasaman Razeghi and Robert L Logan IV and Eric Wallace and Sameer Singh},
  journal={ArXiv},
  year={2020},
  volume={abs/2010.15980}
}
~/papers/AutoPrompt.pdf

@inproceedings{Wallace2019UniversalAT,
  title={Universal Adversarial Triggers for Attacking and Analyzing NLP},
  author={Eric Wallace and Shi Feng and Nikhil Kandpal and Matt Gardner and Sameer Singh},
  booktitle={EMNLP},
  year={2019}
}
https://www.semanticscholar.org/paper/Universal-Adversarial-Triggers-for-Attacking-and-Wallace-Feng/18a1c21f35153c45d0ef30c564bffb7d70a13ccc
~/papers/Wallace2019UniversalAT

@misc{Willison2022PromptIA,
  title={Prompt injection attacks against GPT-3},
  author={Simon Willision},
  year=2022,
  url={https://simonwillison.net/2022/Sep/12/prompt-injection/},
  urldate={October 17, 2022},
}

@article{Xie2022AnEO,
  title={An Explanation of In-context Learning as Implicit Bayesian Inference},
  author={Sang Michael Xie and Aditi Raghunathan and Percy Liang and Tengyu Ma},
  journal={ArXiv},
  year={2022},
  volume={abs/2111.02080}
}

@article{Khashabi2022PromptWT,
  title={Prompt Waywardness: The Curious Case of Discretized Interpretation of Continuous Prompts},
  author={Daniel Khashabi and Shan Lyu and Sewon Min and Lianhui Qin and Kyle Richardson and Sameer Singh and Sean Welleck and Hannaneh Hajishirzi and Tushar Khot and Ashish Sabharwal and Yejin Choi},
  journal={ArXiv},
  year={2022},
  volume={abs/2112.08348}
}

@article{Fedus2021SwitchTS,
  title={Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
  author={William Fedus and Barret Zoph and Noam M. Shazeer},
  journal={ArXiv},
  year={2021},
  volume={abs/2101.03961}
}

@article{Wei2022ChainOT,
  title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
  author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Ed Chi and Quoc Le and Denny Zhou},
  journal={ArXiv},
  year={2022},
  volume={abs/2201.11903}
}

@article{Pearl2001DirectAI,
  title={Direct and Indirect Effects},
  author={Judea Pearl},
  journal={Probabilistic and Causal Inference},
  year={2001}
}
